{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparaison\n",
    "\n",
    "| Fingerprint | R2 | RMSE |  \n",
    "|:-:|:-:|:-:|  \n",
    "|BERT|0.437|2.730| \n",
    "|BERT MSM|0.784|0.883|  \n",
    "| ECFP| 0.765 | 0.9808 |\n",
    "|Can2Can|0.7176|1.073|\n",
    "|Enum2Enum|0.725|1.059|\n",
    "|Transformer|0.862|0.750|\n",
    "| NFP| 0.8845 | 0.6868 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch\n",
    "\n",
    "from bert import BERT\n",
    "from build_vocab import WordVocab\n",
    "from utils import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_index = 0\n",
    "unk_index = 1\n",
    "eos_index = 2\n",
    "sos_index = 3\n",
    "mask_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>unknown</th>\n",
       "      <th>solubility</th>\n",
       "      <th>processed_smiles</th>\n",
       "      <th>spaced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nH0]1c(SC)c2c([nH0]cc[nH0]2)[nH0]c1</td>\n",
       "      <td>6966-78-5</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>[ n H 0 ] 1 c ( S C ) c 2 c ( [ n H 0 ] c c [ ...</td>\n",
       "      <td>[ n H 0 ] 1 c ( S C ) c 2 c ( [ n H 0 ] c c [ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCC(C)Cl</td>\n",
       "      <td>78-86-4</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>C C C ( C ) Cl</td>\n",
       "      <td>C C C ( C ) C l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O=C(NC(=O)c1ccccc1)c1ccccc1</td>\n",
       "      <td>614-28-8</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>O = C ( N C ( = O ) c 1 c c c c c 1 ) c 1 c c ...</td>\n",
       "      <td>O = C ( N C ( = O ) c 1 c c c c c 1 ) c 1 c c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C(C)(C)C)O</td>\n",
       "      <td>464-07-3</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>C C ( C ( C ) ( C ) C ) O</td>\n",
       "      <td>C C ( C ( C ) ( C ) C ) O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O-][N+](c1c(O)cccc1)=O</td>\n",
       "      <td>88-75-5</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>[ O- ] [ N+ ] ( c 1 c ( O ) c c c c 1 ) = O</td>\n",
       "      <td>[ O - ] [ N + ] ( c 1 c ( O ) c c c c 1 ) = O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 SMILES    unknown  solubility  \\\n",
       "0  [nH0]1c(SC)c2c([nH0]cc[nH0]2)[nH0]c1  6966-78-5       -2.36   \n",
       "1                              CCC(C)Cl    78-86-4       -1.96   \n",
       "2           O=C(NC(=O)c1ccccc1)c1ccccc1   614-28-8       -2.27   \n",
       "3                         CC(C(C)(C)C)O   464-07-3       -0.62   \n",
       "4               [O-][N+](c1c(O)cccc1)=O    88-75-5       -1.74   \n",
       "\n",
       "                                    processed_smiles  \\\n",
       "0  [ n H 0 ] 1 c ( S C ) c 2 c ( [ n H 0 ] c c [ ...   \n",
       "1                                     C C C ( C ) Cl   \n",
       "2  O = C ( N C ( = O ) c 1 c c c c c 1 ) c 1 c c ...   \n",
       "3                          C C ( C ( C ) ( C ) C ) O   \n",
       "4        [ O- ] [ N+ ] ( c 1 c ( O ) c c c c 1 ) = O   \n",
       "\n",
       "                                              spaced  \n",
       "0  [ n H 0 ] 1 c ( S C ) c 2 c ( [ n H 0 ] c c [ ...  \n",
       "1                                    C C C ( C ) C l  \n",
       "2  O = C ( N C ( = O ) c 1 c c c c c 1 ) c 1 c c ...  \n",
       "3                          C C ( C ( C ) ( C ) C ) O  \n",
       "4      [ O - ] [ N + ] ( c 1 c ( O ) c c c c 1 ) = O  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/sol_train.csv')\n",
    "df_test = pd.read_csv('data/sol_test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [split(sm) for sm in df_train['SMILES']]\n",
    "y_train = df_train['solubility']\n",
    "x_test = [split(sm) for sm in df_test['SMILES']]\n",
    "y_test = df_test['solubility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = WordVocab.load_vocab('data/vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(sm):\n",
    "    seq_len = 220\n",
    "    ids = [vocab.stoi.get(token, unk_index) for token in sm.split()]\n",
    "    ids = [sos_index] + ids + [eos_index] + [eos_index]\n",
    "    seg = [1]*len(ids)\n",
    "    padding = [pad_index]*(seq_len - len(ids))\n",
    "    ids.extend(padding), seg.extend(padding)\n",
    "    \n",
    "    return ids, seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array(x):\n",
    "    x_id, x_seg = [], []\n",
    "    for sm in x:\n",
    "        a,b = get_inputs(sm)\n",
    "        x_id.append(a)\n",
    "        x_seg.append(b)\n",
    "    return torch.tensor(x_id), torch.tensor(x_seg)\n",
    "    \n",
    "xid_train, xseg_train = get_array(x_train)\n",
    "xid_test, xseg_test = get_array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([322, 220])\n",
      "torch.Size([322, 220])\n"
     ]
    }
   ],
   "source": [
    "print(xid_test.shape)\n",
    "print(xseg_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode to fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (embedding): BERTEmbedding(\n",
       "    (token): TokenEmbedding(45, 256, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (segment): SegmentEmbedding(3, 256, padding_idx=0)\n",
       "    (dropout): Dropout(p=0)\n",
       "  )\n",
       "  (transformer_blocks): ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (dropout): Dropout(p=0)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (dropout): Dropout(p=0)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (dropout): Dropout(p=0)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0)\n",
       "      )\n",
       "      (dropout): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERT(len(vocab), hidden=256, n_layers=4, attn_heads=4, dropout=0)\n",
    "model.load_state_dict(torch.load('../result/GDB17_shuffle//ep_29.pkl'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8030ddffdda4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = BERT(len(vocab), hidden=256, n_layers=2, attn_heads=2, dropout=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../result/GDB17/ep_09.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "#model = BERT(len(vocab), hidden=256, n_layers=2, attn_heads=2, dropout=0)\n",
    "# model = torch.load('../result/MSM_on_GDM17/ep_48.pkl')\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_test, df_train, x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "st,ed = 0,100\n",
    "X_train = model.encode(xid_train[st:ed], xseg_train[st:ed]).detach().numpy()\n",
    "while ed<len(xid_train):\n",
    "    st += 100\n",
    "    ed += 100\n",
    "    X_train = np.vstack([X_train, model.encode(xid_train[st:ed], xseg_train[st:ed]).detach().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "st,ed = 0,100\n",
    "X_test = model.encode(xid_test[st:ed], xseg_test[st:ed]).detach().numpy()\n",
    "while ed<len(xid_test):\n",
    "    st += 100\n",
    "    ed += 100\n",
    "    X_test = np.vstack([X_test, model.encode(xid_test[st:ed], xseg_test[st:ed]).detach().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 220, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.mean(X_train, axis=1)\n",
    "# X_test = np.mean(X_test, axis=1)\n",
    "X_train = X_train[:,0,:]\n",
    "X_test = X_test[:,0,:]\n",
    "#y_train = df_train['solubility']\n",
    "#y_test = df_test['solubility']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.1364\n",
      "Train MSE: 3.5770\n",
      "Test R2: 0.1432\n",
      "Test MSE: 3.4981\n"
     ]
    }
   ],
   "source": [
    "# MEAN\n",
    "MLP = MLPRegressor((1000,1000,1000))\n",
    "MLP.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = MLP.predict(X_train)\n",
    "print(\"Train R2: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Train MSE: {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "y_pred = MLP.predict(X_test)\n",
    "print(\"Test R2: {:.4f}\".format(r2_score(y_test, y_pred)))\n",
    "print(\"Test MSE: {:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.9552\n",
      "Train MSE: 0.1857\n",
      "Test R2: 0.7837\n",
      "Test MSE: 0.8831\n"
     ]
    }
   ],
   "source": [
    "# MEAN\n",
    "MLP = MLPRegressor((1000, 1000, 1000))\n",
    "MLP.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = MLP.predict(X_train)\n",
    "print(\"Train R2: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Train MSE: {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "y_pred = MLP.predict(X_test)\n",
    "print(\"Test R2: {:.4f}\".format(r2_score(y_test, y_pred)))\n",
    "print(\"Test MSE: {:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.7708\n",
      "Train MSE: 0.9495\n",
      "Test R2: 0.6932\n",
      "Test MSE: 1.2527\n"
     ]
    }
   ],
   "source": [
    "# RAW\n",
    "MLP = MLPRegressor((1000, 1000, 1000))\n",
    "MLP.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = MLP.predict(X_train)\n",
    "print(\"Train R2: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Train MSE: {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "y_pred = MLP.predict(X_test)\n",
    "print(\"Test R2: {:.4f}\".format(r2_score(y_test, y_pred)))\n",
    "print(\"Test MSE: {:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2: 0.7592\n",
      "Test MSE: 0.9832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = MLP.predict(X_test)\n",
    "print(\"Test R2: {:.4f}\".format(r2_score(y_test, y_pred)))\n",
    "print(\"Test MSE: {:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7507329751649384"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5636**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:  3.0min finished\n",
      "/home/honda/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=8,\n",
       "       param_grid={'hidden_layer_sizes': [(10, 10), (50, 50), (100, 100), (500, 500), (1000, 1000), (10, 10, 10), (50, 50, 50), (100, 100, 100), (500, 500, 500), (1000, 1000, 1000)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = { \"hidden_layer_sizes\": [(10, 10), (50,50), (100, 100), (500, 500), (1000, 1000),(10,10,10), (50,50,50), (100,100,100), (500,500,500), (1000,1000,1000)]}\n",
    "MLP_grid = GridSearchCV(estimator=MLPRegressor(), param_grid=param_grid, cv=5, verbose=1, n_jobs=8)\n",
    "MLP_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': (100, 100, 100)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train : 2.362, test : 2.382\n",
      "R2 train : 0.430, test : 0.417\n"
     ]
    }
   ],
   "source": [
    "MLP_grid.best_estimator_.fit(X_train, y_train)\n",
    "y_train_pred = MLP_grid.best_estimator_.predict(X_train)\n",
    "y_test_pred = MLP_grid.best_estimator_.predict(X_test)\n",
    "\n",
    "print('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)) )\n",
    "print('R2 train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.059245014149229"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.122**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/honda/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train : 0.224, test : 1.200\n",
      "R2 train : 0.946, test : 0.706\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = RF.predict(X_train)\n",
    "y_test_pred = RF.predict(X_test)\n",
    "\n",
    "print('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)) )\n",
    "print('R2 train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \"max_depth\": [2,5,10, None],\n",
    "                \"n_estimators\": [10,50,100,300],\n",
    "                \"max_features\": [1, 3, 10],\n",
    "                \"min_samples_split\": [2, 3, 10],\n",
    "                \"min_samples_leaf\": [1, 3, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  52 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 352 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=8)]: Done 852 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=8)]: Done 1532 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=8)]: Done 1982 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 2160 out of 2160 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=8,\n",
       "       param_grid={'max_depth': [2, 5, 10, None], 'n_estimators': [10, 50, 100, 300], 'max_features': [1, 3, 10], 'min_samples_split': [2, 3, 10], 'min_samples_leaf': [1, 3, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_grid = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, cv=5, n_jobs=8, verbose=1)\n",
    "RF_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train : 0.163, test : 1.177\n",
      "R2 train : 0.961, test : 0.712\n"
     ]
    }
   ],
   "source": [
    "RF_grid.best_estimator_.fit(X_train, y_train)\n",
    "y_train_pred = RF_grid.best_estimator_.predict(X_train)\n",
    "y_test_pred = RF_grid.best_estimator_.predict(X_test)\n",
    "\n",
    "print('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)) )\n",
    "print('R2 train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
